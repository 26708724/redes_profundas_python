{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67RBrvkUviuj"
      },
      "source": [
        "<a href=\"https://www.inove.com.ar\"><img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/PA%20Banner.png\" width=\"1000\" align=\"center\"></a>\n",
        "\n",
        "\n",
        "# Ejercicio de clasificación con redes neuronales profundas (DNN)\n",
        "\n",
        "Ejemplo de clasificación utilizando redes neuronales para la clasificación de imagenes<br>\n",
        "\n",
        "v1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Objetivos**\n",
        "*   Estudiar el dataset de mnist que contiene 70.000 imagenes de números escritos a mano.\n",
        "* Visualizar las imágenes a analizar.\n",
        "* Normalizar la imágenes.\n",
        "* Comparar tres redes neuronales.\n",
        "* Transformar la salida a categorical.\n",
        "* Construir, entrenar y evaluar al modelo con una Red Neuronal.\n",
        "* Validar el modelo con una imagen externa."
      ],
      "metadata": {
        "id": "tp2PV9HH0aw5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2sSeyEovSw-"
      },
      "source": [
        "#Librerias a implementar\n",
        "import os\n",
        "import platform\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "#from keras.utils import to_categorical  \n",
        "from keras.utils.np_utils import to_categorical # Si esto no funciona, probar con el import anterior\n",
        "\n",
        "import matplotlib.image as mpimg "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Szo7P_3v00C"
      },
      "source": [
        "# Recolectar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline1.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `MNIST dataset`\n",
        "Contiene 70.000 imagenes de números escritos a mano (números del 0 al 9, 10 dígitos). Cada imagen es de 28x28 píxeles en escala de grises (1 canal o 1 nivel de profundidad). Es uno de los dataset más utilizados para poner a prueba algoritmos de clasificación de imagenes.<br> [Dataset source](https://keras.io/api/datasets/mnist/)\n",
        "- La entrada (X) es una variable imagen de 28x28\n",
        "- La salida (y) es el dígito que representa la imagen en cuestión, un número de 0 al 9\n"
      ],
      "metadata": {
        "id": "4r2C2tGv0rMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Código de carga del dataset mnist"
      ],
      "metadata": {
        "id": "ZH8K9Ti20jfJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnVpNGuAvyFi"
      },
      "source": [
        "# Importar mnist de keras.datasets\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Leer el dataset de mnist.\n",
        "# Viene con los datos separados para entrenar y evaluar.\n",
        "# De objeto importado  \"mnist\" utilizar el método load_data()\n",
        "(data_X_train, data_y_train), (data_X_test, data_y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGbCJanFR8oL"
      },
      "source": [
        "# plt alias de Matplotlib.\n",
        "# Método figure() crea el espacio para dibujar.\n",
        "# Con figsize=(16,9) se define el ancho y alto del dibujo\n",
        "fig = plt.figure(figsize=(16,9))\n",
        "\n",
        "# Bucle que itera 50 veces para mostrar las primeras 50 imágenes del dataset\n",
        "for i in range(50):\n",
        "    \n",
        "    # ax gráfico que mostrará las imágenes en 5 filas y 10 columnas\n",
        "    # En cada iteración va ubicando la imagen en la siguiente posición (i+1)\n",
        "    ax = fig.add_subplot(5, 10, i+1)\n",
        "    \n",
        "    # .axis('off') elimina el recuadro de cada imagen\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Muestra las 50 imágenes de la variable data_X_train en el espacio del dibujo\n",
        "    plt.imshow(data_X_train[i], cmap='Greys')\n",
        "\n",
        "# Muestra la figura\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u7UhhVKR2qu"
      },
      "source": [
        "# plt, alias de Matplotlib \n",
        "# Muestra la primer imagen (data_X_train[0] )de la variable data_X_train en el espacio del dibujo.\n",
        "# cmap='gray', escala de grises\n",
        "plt.imshow(data_X_train[0], cmap='gray')\n",
        "\n",
        "# Agrega título concatenando el número a mostrar de la primer posición\n",
        "plt.title(\"Número: \" + str(data_y_train[0]))\n",
        "\n",
        "# Muestra la imagen\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHHsGe1Qypde"
      },
      "source": [
        "# Procesar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline2.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvzaKBMbyoiy"
      },
      "source": [
        "# Observar como está representada la imagen, ver fila del medio (14)\n",
        "# data_X_train[0] información de la primer imagen\n",
        "# [14, :] muestra la fila 14 y todas las columnas (:)\n",
        "print(data_X_train[0][14, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw9HbE88y3wu"
      },
      "source": [
        "# Por los resultados podemos ver que la imagen está representada de 0 a 255\n",
        "# Normalizamos los datos para que se encuentren entre 0 y 1\n",
        "X_train_norm = data_X_train / 255\n",
        "X_test_norm = data_X_test / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LirgXKpiy8dr"
      },
      "source": [
        "# shape[0], devuelve cantidad de datos en observacion de la primer imagen.\n",
        "print('Cantidad de datos en observacion:', X_train_norm.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-HTzboa4q-5"
      },
      "source": [
        "# Muetra las dimensiones de la primer imagen normalizada.\n",
        "print('Tamaño de la imagen:', X_train_norm[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BnzYdlRzBxz"
      },
      "source": [
        "# Explorar datos\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline3.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uWcuzLX58Z9"
      },
      "source": [
        "# Observar el los primeros 10 datos del dataset de y_train\n",
        "print(data_y_train[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploramos los primeros diez 8 del dataset para train"
      ],
      "metadata": {
        "id": "RxFHFZQh2c__"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2w_eW5QI-hf"
      },
      "source": [
        "# plt alias de Matplotlib.\n",
        "# Método figure() crea el espacio para dibujar.\n",
        "# Con figsize=(16,9) se define el ancho y alto del dibujo\n",
        "fig = plt.figure(figsize=(16,9))\n",
        "\n",
        "#contador\n",
        "j = 0\n",
        "\n",
        "# Itera 10 veces\n",
        "for i in range(10):\n",
        "\n",
        "    # ax, gráfico que mostrará las imágenes en 1 filas y 10 columnas\n",
        "    # En cada iteración va ubicando la imagen en la siguiente posición (i+1)\n",
        "    ax = fig.add_subplot(1, 10, i+1)\n",
        "\n",
        "    # .axis('off') elimina el recuadro de cada imagen\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Bucle que verifica que la imagen sea igual a 8\n",
        "    while True:\n",
        "        if data_y_train[j] == 8:\n",
        "\n",
        "            # Muestra la imagen con escala de grises\n",
        "            ax.imshow(X_train_norm[j], cmap='Greys')\n",
        "            j += 1\n",
        "            break\n",
        "        j += 1\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploramos los primeros diez 8 del dataset para test"
      ],
      "metadata": {
        "id": "7cN3p8GY2ggp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvDJ8sx85JAH"
      },
      "source": [
        "# plt alias de Matplotlib.\n",
        "# Método figure() crea el espacio para dibujar.\n",
        "# Con figsize=(16,9) se define el ancho y alto del dibujo\n",
        "fig = plt.figure(figsize=(16,9))\n",
        "\n",
        "#contador\n",
        "j = 0\n",
        "\n",
        "# Itera 10 veces\n",
        "for i in range(10):\n",
        "\n",
        "    # ax, gráfico que mostrará las imágenes en 1 filas y 10 columnas\n",
        "    # En cada iteración va ubicando la imagen en la siguiente posición (i+1)\n",
        "    ax = fig.add_subplot(1, 10, i+1)\n",
        "\n",
        "    # .axis('off') elimina el recuadro de cada imagen\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Bucle que verifica que la imagen sea igual a 8\n",
        "    while True:\n",
        "        if data_y_test[j] == 8:\n",
        "                        \n",
        "            # Muestra la imagen en escala de grises\n",
        "            ax.imshow(X_test_norm[j], cmap='Greys')\n",
        "            j += 1\n",
        "            break\n",
        "        j += 1\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUs6mDw67LAQ"
      },
      "source": [
        "#### Transformar los imagenes de 28x28 (2 dimensiones) en un array de una dimensión (28x28 = 784)\n",
        "Esto se realiza porque las redes neuronales no soportan que se ingrese un array de dos dimensiones, solo soportan ingresar \"N\" features (un array)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aODNf0SoPyK"
      },
      "source": [
        "# proceso de flatten --> transformar las imagenes en un vector de 1 dimension\n",
        "# shape devuelve filas y columnas\n",
        "# Multiplica las filas por columnas (X_train_norm.shape[1] * X_train_norm.shape[2])\n",
        "num_pixels = X_train_norm.shape[1] * X_train_norm.shape[2]\n",
        "\n",
        "# X_train_norm.reshape(X_train_norm.shape[0], num_pixels) Ajusta el array a dos dimensiones\n",
        "# Tipo de dato (astype('float32'))\n",
        "X_train = X_train_norm.reshape(X_train_norm.shape[0], num_pixels).astype('float32')\n",
        "X_test = X_test_norm.reshape(X_test_norm.shape[0], num_pixels).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ8aVPG07xqF"
      },
      "source": [
        "# ¿Cómo se ve ahora nuestra primera imagen?\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot()\n",
        "\n",
        "# Muestra la primer imagen de X_train con un ajuste .reshape(-1,1) y con escala de grises\n",
        "ax.imshow(X_train[0].reshape(-1,1).T, cmap='gray')\n",
        "\n",
        "# Escala de números en el eje de las x como potencia de base 10\n",
        "ax.set_xscale(\"log\")\n",
        "\n",
        "# Agrega titulo\n",
        "plt.title(\"Número: \" + str(data_y_train[0]))\n",
        "\n",
        "# Muetra la imagen\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOnLxPyC8PtG"
      },
      "source": [
        "# Devuelve información de la imagen.\n",
        "print('Datos en observacion:', X_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQOAyB-M8W_P"
      },
      "source": [
        "Son 60000 vectores, cada vector representa lo mismo que una fila de un dataset. Cada fila o vector tiene 784 columnas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3lQU6J_8Hd8"
      },
      "source": [
        "print('Dimensión de cada imagen faltten:', X_train[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z_SuZlj3gbQ"
      },
      "source": [
        "# Entrenar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline4.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntY84fHj3q5q"
      },
      "source": [
        "Los datos ya estan dividios en train y test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vdIz9_r-sMe"
      },
      "source": [
        "# Transformar la salida a oneHotEncoding con to_categorical\n",
        "y_train = to_categorical(data_y_train)\n",
        "y_test = to_categorical(data_y_test)\n",
        "\n",
        "# Muestra los 10 primeros to_categorical\n",
        "y_train[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Wb3oMvn-mIF"
      },
      "source": [
        "# input shape (almacena la cantidad de pixeles de las imagen)\n",
        "in_shape = X_train.shape[1]\n",
        "in_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpYcXh1g_N3Q"
      },
      "source": [
        "# output shape, almacena la cantidad de número identificados en el dataset.\n",
        "out_shape = y_train.shape[1]\n",
        "out_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu1u9JhXq9Dy"
      },
      "source": [
        "# Se importa Dense de la librería tensorflow.keras.layers\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# Se crea el objeto model a partir de la clase Sequential()\n",
        "model = Sequential()\n",
        "\n",
        "# Se crea la capa de entrada y las capas ocultas de la red, que tendrá:\n",
        "# --> tantas entradas (input_shape) como columnas (in_shape), se especifica en la primera capa\n",
        "# --> tantas neuronas como deseemos (units)\n",
        "# --> utilizamos \"relu\" como capa de activación\n",
        "model.add(Dense(units=64, activation='relu', input_shape=(in_shape,)))\n",
        "\n",
        "# Se agregan dos capas más con las mismas neuronas y función de activación units=64, activation='relu'\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "\n",
        "# Se crea la capa de salida, que tendrá tantas neuronas como salidas posibles\n",
        "# Se implementa 'softmax' ya que la salida es multiple\n",
        "model.add(Dense(units=out_shape, activation='softmax'))\n",
        "\n",
        "# Configuración del modelo para el entrenamiento, implementando el método compile a partir del modelo creado.\n",
        "# Se necesita indicar los parámetros:\n",
        "# optimizer, nombre del optimizador (es el algoritmo que se encarga del descenso de gradiente estocástico)\n",
        "# Fuente: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
        "# loss, se llama función de pérdida, representa las categorías conocidas de las predicción. Al ser 'categorical_crossentropy' \n",
        "#la predicción tiene una salida con varias opciones.\n",
        "# metrics, se define la métrica que evaluará el modelo durante el entrenamiento y las pruebas.\n",
        "model.compile(optimizer=\"Adam\",\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Resumen de la estructura de la red profunda.\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_89g3dSm2wf"
      },
      "source": [
        "# Se entrena el modelo con el método fit\n",
        "# Necesita definir los valores para X_train, y_train sumado a la cantidad de épocas que seria la iteraciones de entrenamiento.\n",
        "# dirigido a validación (validation_split=0.2)\n",
        "# batch_size, tamaño del lote a entrenar.\n",
        "history = model.fit(X_train, y_train, validation_split=0.2 , epochs=10, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDuagYJHvNlm"
      },
      "source": [
        "# Variable epoch_count, que almacena en una lista la cantidad de épocas de train\n",
        "# history, es la variable que almacena las predicciones del modelo\n",
        "# y de ella, se puede acceder a información como su historial (history) del accuracy\n",
        "epoch_count = range(1, len(history.history['accuracy']) + 1)\n",
        "\n",
        "# De Seaborn (sns) se accede al gráfico de línea para representar;\n",
        "# Por un lado, el 'accuracy',\n",
        "# Por el otro, la validación (val_accuracy)\n",
        "sns.lineplot(x=epoch_count,  y=history.history['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=history.history['val_accuracy'], label='valid')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF15cAnvi0L1"
      },
      "source": [
        "Se puede observar que el modelo con más capas ocultas tienen menos parámetros para entrar porque la capa expuesta a la entrada tiene menos neuronas.\n",
        "Pero, al aumentar la complejidad de la red con más capas profundas el sistema produce overfitting, deja de aprender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xERthbSjP_L"
      },
      "source": [
        "# Para arreglar esto se utiliza regularizacion, que es el proceso por el cual\n",
        "# el sistema tiene la capacidad de \"apagar\" neuronas de las capas y buscar\n",
        "# el modelo que mejor funcione.\n",
        "\n",
        "# Se crea el objeto model a partir de la clase Sequential()\n",
        "model = Sequential()\n",
        "\n",
        "# Se seleccionó que se apagen el 20% de la neurona de la capa\n",
        "# A este número se lo obtuvo realizando diferentes pruebas, en general se\n",
        "# ensaya con --> 0.2, 0.5 y 0.8\n",
        "dropout_rate = 0.2\n",
        "\n",
        "# Red neuronal que tiene 4 capas densas y dos de dropout\n",
        "model.add(Dense(units=64, activation='relu', input_shape=(in_shape,)))\n",
        "\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "model.add(Dense(units=out_shape, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=\"Adam\",\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arA74ZVjjafe"
      },
      "source": [
        "# Se entrena el modelo con el método fit\n",
        "# Necesita definir los valores para X_train, y_train sumado a la cantidad de épocas que seria la iteraciones de entrenamiento.\n",
        "# dirigido a validación (validation_split=0.2)\n",
        "# batch_size, tamaño del lote a entrenar.\n",
        "history = model.fit(X_train, y_train, validation_split=0.2 , epochs=10, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yooziVp2jffZ"
      },
      "source": [
        "# Variable epoch_count, que almacena en una lista la cantidad de épocas de train\n",
        "# history, es la variable que almacena las predicciones del modelo\n",
        "# y de ella, se puede acceder a información como su historial (history) del accuracy\n",
        "epoch_count = range(1, len(history.history['accuracy']) + 1)\n",
        "\n",
        "# De Seaborn (sns) se accede al gráfico de línea para representar;\n",
        "# Por un lado, el 'accuracy',\n",
        "# Por el otro, la validación (val_accuracy)\n",
        "sns.lineplot(x=epoch_count,  y=history.history['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=history.history['val_accuracy'], label='valid')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7a6463ZiHW2"
      },
      "source": [
        "# Al apagar neuronas de las capas se puede seguir aumentando la complejidad\n",
        "# para ensayar\n",
        "model = Sequential()\n",
        "\n",
        "# Se seleccionó que se apagen el 20% de la neurona de la capa\n",
        "# A este número se lo obtuvo realizando diferentes pruebas, en general se\n",
        "# ensaya con --> 0.2, 0.5 y 0.8\n",
        "dropout_rate = 0.2\n",
        "\n",
        "# Red neuronal que tiene 7 capas densas y 5 de dropout\n",
        "model.add(Dense(units=64, activation='relu', input_shape=(in_shape,)))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(rate=dropout_rate))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(rate=dropout_rate))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(rate=dropout_rate))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(rate=dropout_rate))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(rate=dropout_rate))\n",
        "model.add(Dense(units=out_shape, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=\"Adam\",\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8trLC3fiNVM"
      },
      "source": [
        "# Se entrena el modelo con el método fit\n",
        "# Necesita definir los valores para X_train, y_train sumado a la cantidad de épocas que seria la iteraciones de entrenamiento.\n",
        "# dirigido a validación (validation_split=0.2)\n",
        "# batch_size, tamaño del lote a entrenar.\n",
        "history = model.fit(X_train, y_train, validation_split=0.2 , epochs=10, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32KruDWjiM-B"
      },
      "source": [
        "# Variable epoch_count, que almacena en una lista la cantidad de épocas de train\n",
        "# history, es la variable que almacena las predicciones del modelo\n",
        "# y de ella, se puede acceder a información como su historial (history) del accuracy\n",
        "epoch_count = range(1, len(history.history['accuracy']) + 1)\n",
        "\n",
        "# De Seaborn (sns) se accede al gráfico de línea para representar;\n",
        "# Por un lado, el 'accuracy',\n",
        "# Por el otro, la validación (val_accuracy)\n",
        "sns.lineplot(x=epoch_count,  y=history.history['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=history.history['val_accuracy'], label='valid')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL0_TMz7Em4o"
      },
      "source": [
        "# Variable y_hat_prob que almacena las probabilidades de las predicciones\n",
        "# con los datos de evaluación\n",
        "y_hat_prob = model.predict(X_test)\n",
        "y_hat_prob[:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxs4EZSBAZoh"
      },
      "source": [
        "# Muestra las clasificación de cada imagen, de acuerdo a la probabilidad más alta.\n",
        "y_hat = np.argmax(y_hat_prob,axis=1)\n",
        "y_hat[:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3IfjUuI4XnD"
      },
      "source": [
        "# Validar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline5.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnXeXHwdyHVx"
      },
      "source": [
        "# Calcular la exactitud (accuracy)\n",
        "scores = model.evaluate(X_test, y_test)\n",
        "scores[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeLeYLYz6ZhO"
      },
      "source": [
        "# Se utiliza la matriz de confusión para evaluar la precisión de una clasificación.\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Necesita dos variables que contengan los valores a comparar\n",
        "cm = confusion_matrix(y_test.argmax(axis=1), y_hat)\n",
        "\n",
        "# Código para realizar la representación gráfica con los resultados\n",
        "# Se crea la varible cmd, que almacena visualization de la Confusion Matrix \n",
        "# Necesita la variable cm que contiene los resultados de la comparación entre los valores reales y predicción\n",
        "# display_labels, se especifica las etiquetas de las categorias que se evalúan.\n",
        "cmd = ConfusionMatrixDisplay(cm, display_labels=list(range(10)))\n",
        "\n",
        "# Con cmd.plot se especifica el mapa de colores reconocido por matplotlib.\n",
        "cmd.plot(cmap=plt.cm.Blues)\n",
        "\n",
        "# Mostrar la figura\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dZxGbjG96jR"
      },
      "source": [
        "# Utilizar modelo\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline6.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6Tc5nBqbow8"
      },
      "source": [
        "Se utiliza el ranking de los peores 10 números clasificados con una ANN para evaluar contra este nuevo modelo de red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noOsuU6Tb4GZ"
      },
      "source": [
        "# Ubicación de los peores ochos por indice\n",
        "ranking_10 = [8183, 6765, 8522, 1325, 582, 9280, 5749, 3567, 3206, 9744]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cefy3ktFb6j6"
      },
      "source": [
        "# Obtener los vectores para evaluar\n",
        "# Ubica el vector de cada imagen por su ubicación\n",
        "X_test_peores = X_test[ranking_10]\n",
        "\n",
        "# Ubica el número que corresponde a cada imagen por su ubicación\n",
        "y_test_peores = y_test[ranking_10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB1tr2blcKpB"
      },
      "source": [
        "# Calcular la exactitud\n",
        "score = model.evaluate(X_test_peores, y_test_peores)\n",
        "score[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBfhuPeccbGP"
      },
      "source": [
        "# ¿Qué es lo que el sistema ve?\n",
        "\n",
        "# Predicción\n",
        "y_hat_prob_peores = model.predict(X_test_peores)\n",
        "\n",
        "# Ubica de acuerdo a la probabilidad más alta cuál es el número que le corresponde.\n",
        "y_hat_peores = np.argmax(y_hat_prob_peores,axis=1)\n",
        "y_hat_peores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAxkIcGXcpLS"
      },
      "source": [
        "# Espacio para dibujar\n",
        "fig = plt.figure(figsize=(16,9))\n",
        "\n",
        "# Contador\n",
        "j = 0\n",
        "\n",
        "for i in ranking_10:\n",
        "\n",
        "    # ax, gráfico que mostrará las imágenes en 1 filas y 10 columnas\n",
        "    # En cada iteración va ubicando la imagen en la siguiente posición (i+1)\n",
        "    ax = fig.add_subplot(1, 10, j+1)\n",
        "\n",
        "    # .axis('off') elimina el recuadro de cada imagen\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Muestra la imagen en escala de grises\n",
        "    ax.imshow(X_test_norm[i], cmap='Greys')\n",
        "    j += 1\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prueba con imagen externa (Dibujar un número en paint con fondo negro y número en blanco)"
      ],
      "metadata": {
        "id": "wEa-hoRjJzOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leer la imagen \n",
        "img1 = mpimg.imread('/content/cuatro.jpg')\n",
        "\n",
        "# Mostrar la imagen\n",
        "plt.imshow(img1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FJq5EgCQJ8aF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ver las dimensiones de la imagen cargada\n",
        "img1.shape"
      ],
      "metadata": {
        "id": "HSB3zwCSLWOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función que extrae los canales de color\n",
        "def rgb2gray(rgb):\n",
        "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])"
      ],
      "metadata": {
        "id": "H7vqSGDbuL2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se invoca la función y se le pasa la imagen\n",
        "gray = rgb2gray(img1)  \n",
        "gray.shape"
      ],
      "metadata": {
        "id": "itTw-wh2uOmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Debemos ahora quitar los canales de color para que sea en escala de grises\n",
        "def rgb2gray(rgb):\n",
        "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
        "\n",
        "# Se invoca la función\n",
        "gray = rgb2gray(img1)    \n",
        "\n",
        "# cmap='gray', variación de colores en grises, indicando los valores máximo y mínimo de la escala de colores.\n",
        "plt.imshow(gray, cmap='gray', vmin=0, vmax=255)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6-doJ5k82heF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Modificando las dimensiones de la imagen para que sea 28x28\n",
        "copi_img = gray[:,:28]\n",
        "copi_img.shape"
      ],
      "metadata": {
        "id": "Io_t48zTLYb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesar la imagen\n",
        "# Normalizar\n",
        "img_norm = copi_img / 255.0\n",
        "\n",
        "# Calcular el número de pixeles de la imagen.\n",
        "num_pixel = img_norm.shape[0] * img_norm.shape[1]\n",
        "num_pixel"
      ],
      "metadata": {
        "id": "43IjG6HTLard"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar la imagen en una fila.\n",
        "img_prueba = img_norm.reshape(1,num_pixel).astype('float32')\n",
        "img_prueba.shape"
      ],
      "metadata": {
        "id": "mlT_J8rrLfI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ¿Qué es lo que el sistema ve?\n",
        "# Predicción\n",
        "prediccion = model.predict([img_prueba])\n",
        "prediccion[0]"
      ],
      "metadata": {
        "id": "6iDbelLzLhhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Muestra las clasificación de cada imagen, de acuerdo a la probabilidad más alta.\n",
        "y_prediccion = np.argmax(prediccion,axis=1)\n",
        "y_prediccion[0]"
      ],
      "metadata": {
        "id": "lkN4oFMjMcHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7yzVZcZ9-4m"
      },
      "source": [
        "# Conclusión\n",
        "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline7.png\" width=\"1000\" align=\"middle\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWAReOgo-B7b"
      },
      "source": [
        "Al utilizar deep larning, redes profundas, logramos obtener un mejor resultado. __PERO!__ Al utilizar más capas fue necesario el proceso de regularización con dropout para poder evitar que un modelo más complejo produza overfiting. <br>\n",
        "Este modelo sigue siendo incapaz de manejar imagenes a color debido a la necesidad del proceso de flatten."
      ]
    }
  ]
}